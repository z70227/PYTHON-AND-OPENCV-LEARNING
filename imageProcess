#使用OPENCV读取图片
import numpy as np
import cv2
import matplotlib.pyplot as plt
#matplotlib inline

img = cv2.imread('link.jpg')
print(img.shape)
#使用matplotlib展示图片
plt.imshow(img)
#图片为什么会这样，因为OPENCV默认的是BGR编码，而系统默认的是RGB

import numpy as np
import cv2
#将BGR转化为RGB，方法一数组操作
fig = plt.figure(figsize=(12,8))
ax1 = fig.add_subplot(121)
ax2 = fig.add_subplot(122)
#ax1.imshow(img[:,:,np.array([2,1,0])])
ax2.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))

import cv2
import seaborn as sns
img_jizhiQR = cv2.imread("3.png")
img_jizhiQR = cv2.cvtColor(img_jizhiQR,cv2.COLOR_BGR2GRAY)
print(img_jizhiQR.shape)

#将120*120的图像映射成25*25
#规定220个坐标点，分别对应到25个坐标点上
np_220to25_idx = np.linspace(0,24.9,220).astype(np.int)

#对两个维度一起规定，如此220*220二维平面上的每个点就都有了25*25的映射
np_220to25_mesh = np.meshgrid(np_220to25_idx,np_220to25_idx)
np_25_counts = np.zeros([25,25])
for row_idx in range(220) :
    for col_idx in range(220) :
        col_num_25 = np_220to25_mesh[0][row_idx][col_idx]
        row_num_25 = np_220to25_mesh[1][row_idx][col_idx]
        if img_jizhiQR[row_idx][col_idx] ==255:
            #如果原先是白色，则这里25*25矩阵中对应点+1
            np_25_counts[row_num_25][col_num_25] += 1;
#统计25*25矩阵中每个点有多少在映射前是白色
sns.set_style('white')
sns.distplot(np_25_counts.ravel())

#读取图片
img_jizhiQR = cv2.imread("jizhi_qinding.png")
img_jizhiQR = img_jizhiQR[:,:,::-1]

#去掉白色边缘
img_jizhiQR_gray = cv2.cvtColor(img_jizhiQR,cv2.COLOR_RGB2GRAY)
np_totalRow = np.arange(img_jizhiQR.shape[0])#记下一共多少行

idx_rowUsed = np_totalRow[img_jizhiQR_gray.mean(0) != 255]#记录每行每列的平均值不是255的TURE
idx_colUsed = np_totalRow[img_jizhiQR_gray.mean(1) != 255]
img_jizhiQR_rmBlank = img_jizhiQR[idx_rowUsed,:,:][:,idx_colUsed,:]#去掉每行每列平均值是255的行和列

#去掉中间蓝色部分，即新建一个空白矩阵，然后将原先矩阵是黑色的部分在新阵中设为255
img_jizhiQR_new = np.zeros([img_jizhiQR_rmBlank.shape[0],img_jizhiQR_rmBlank.shape[1]]) + 255
idx_black = (img_jizhiQR_rmBlank[:,:,0]<10)*(img_jizhiQR_rmBlank[:,:,1]<10)*(img_jizhiQR_rmBlank[:,:,2]<10)

img_jizhiQR_new[idx_black] =0

#用TF池化函数，将二维码大小减小到29*29
np_25_counts_tf = AvgPool(img_jizhiQR_new,29)

fig = plt.figure(figsize=(15,5))
ax1 = fig.add_subplot(131) 
ax2 = fig.add_subplot(132) 
ax3 = fig.add_subplot(133)

ax1.imshow(img_jizhiQR)
ax2.imshow(img_jizhiQR_new)
ax3.imshow(np_25_counts_tf)

#使用OPENCV“抠图”——基于颜色通道以及形态特征
img = cv2.imread('messi5.jpg')
img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
ball = img[280:340,330:390]#从原图中截取足球
plt.imshow(ball)
#img_gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)
#plt.imshow(img_gray,cmap="gray")

#利用OPENCV抠图，首先观察数据。这个球具有以下特点：1.看起来是圆形。2.颜色是黄色+苍蓝色。3.背景是绿色。
#所以可以确定以下思路：1.识别圆形的算法——HOUGH算法。2.用黄色+藏蓝色将球从背景提取出来。3.用绿色过滤背景。

#利用OPENCV抠图，首先观察数据。这个球具有以下特点：1.看起来是圆形。2.颜色是黄色+苍蓝色。3.背景是绿色。
#所以可以确定以下思路：1.识别圆形的算法——HOUGH算法。2.用黄色+藏蓝色将球从背景提取出来。3.用绿色过滤背景。
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(332)
#print(ball.reshape(-1,3).shape)#我们不知道z的shape属性是多少，
                               #但是想让z变成只有3列，行数不知道多少，
                               #通过`z.reshape(-1,3)`，Numpy自动计算出有3600行，
                               #新的数组shape属性为(3600, 3)，与原来的(60, 60，3)配套。
for r in ball.reshape(-1,3):
    ax.plot(r[1],r[0],'.',c=(r[0]/255.,r[1]/255.,r[2]/255.))

ax = fig.add_subplot(333)
for r in ball.reshape(-1,3):
    ax.plot(r[2],r[1],'.',c=(r[0]/255.,r[1]/255.,r[2]/255.))
    
ax = fig.add_subplot(336)
for r in ball.reshape(-1,3):
    ax.plot(r[2],r[0],'.',c=(r[0]/255.,r[1]/255.,r[2]/255.))
    
for i,color in enumerate(["Red","Green","Blue"]):
    ax = fig.add_subplot(3,3,i*3+i+1)
    ax.text(5,5,color)
    ax.plot(0,0)
    ax.plot(10,10)
    ax.set_xlim(0,10)
    ax.set_ylim(0,10)
    ax.axis('off')
    
#图为ball各像素点RGB的分布情况，图中的黄色与蓝黑色均为足球的颜色，而绿色式足球场的颜色，接下来需要寻找一个规则来区分足球与足球场

#现在得到了圆形的边缘，接下来进行圆形检测
gray = img_sob+255
#首先用CANNY算子过滤边缘
canny = cv2.Canny(gray,200,300)

#其次用中位数进行卷积操作，平滑颜色梯度（中值滤波）
gray = cv2.medianBlur(gray,5)
#plt.imshow(gray,"gray")
#最后用HOUGHCIRCLES函数检测圆形物体
np_hc = cv2.HoughCircles(gray,cv2.HOUGH_GRADIENT,dp=1,minDist=60,param1=200,param2=10,minRadius=20,maxRadius=30)

#展示结果
fig = plt.figure()
ax = fig.add_subplot(111)
ax.imshow(img_sob,"gray")
img_tmp = np_hc

for i in range(np_hc.shape[1]):
    img_tmp = cv2.circle(img,(np_hc[0,i,0],np_hc[0,i,1]),np_hc[0,i,2],(255,0,0),8)
plt.imshow(img_tmp)

import cv2
img = cv2.imread('p11.jpg')
img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
img_gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)
fig = plt.figure(figsize=(20,10))
#pix_per_cell是指多少个像素作为一个网格来计算，这个值越高，切出来的网格数就越少，整个HOG的结果就越粗略
#cell_per_block是指一个网格内使用几个方向指针，如果是十字交叉的情况，则至少需要两个方向指针进行交叉，才可以表示出十字
#orient是指切出来的网格有几种方向走势，如果是4则是上下左右，如果是8就再增加上左，上右，下左，下右
for i1,pix_per_cell in enumerate([6,8,10]):
    for i2,cell_per_block in enumerate([2,3]):
        for i3,orient in enumerate([6,8,9]):
            features, hog_image = hog(img_gray, pixels_per_cell=(pix_per_cell,pix_per_cell), 
                               cells_per_block=(cell_per_block,cell_per_block),
                               orientations=orient, visualise=True, feature_vector=False
                         )
            #print(features.shape)
            ax = fig.add_subplot(3,6,i1*6+i2*3+i3+1)
            ax.imshow(hog_image, 'gray')
            ax.set_title("Pix%d_C%d_Ori%d" % (pix_per_cell, cell_per_block, orient))
